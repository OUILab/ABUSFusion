{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8654b2e4-db66-4fd8-a698-e5495ee68605",
   "metadata": {},
   "source": [
    "# Ultrasound Frame Corner Prediction with Optical Flow and IMU Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea20b6-550d-4e4c-b031-b423dbb538a5",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a0af4-1848-4b95-898e-1f59a1f439d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torchvision.models.optical_flow import (\n",
    "    Raft_Large_Weights,\n",
    "    Raft_Small_Weights,\n",
    "    raft_large,\n",
    "    raft_small,\n",
    ")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c538c91-5d76-4c22-b68d-d88cc533ab13",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe904be-b294-4fc6-b175-76529312c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_hdf(file_path)\n",
    "\n",
    "\n",
    "file_path = \"/home/varun/xia_lab/repos/ABUSFusion/scans/20240826/wrist_data.h5\"\n",
    "df = load_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332ba9d-2ff9-41be-bf24-6ca01ac1bd05",
   "metadata": {},
   "source": [
    "## 3. Calculate Frame Corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b66651-f167-4ad5-b06b-08adbd88f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frame_corners(df, width, height, marker_to_probe_bottom):\n",
    "    corners_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract position and quaternion\n",
    "        position = np.array([row[\"ot_pos_x\"], row[\"ot_pos_y\"], row[\"ot_pos_z\"]])\n",
    "        quaternion = np.array([row[\"ot_qw\"], row[\"ot_qx\"], row[\"ot_qy\"], row[\"ot_qz\"]])\n",
    "\n",
    "        # Convert quaternion to rotation matrix\n",
    "        rotation_matrix = Rotation.from_quat(quaternion).as_matrix()\n",
    "\n",
    "        # Define frame corners in probe coordinates (y: axial, x: lateral, z: elevational)\n",
    "        frame_corners = np.array(\n",
    "            [\n",
    "                [0, 0, 0],  # Top-left\n",
    "                [width, 0, 0],  # Top-right\n",
    "                [0, height, 0],  # Bottom-left\n",
    "                [width, height, 0],  # Bottom-right\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Transform to align with optical tracker coordinates\n",
    "        transform_matrix = np.array(\n",
    "            [\n",
    "                [0, 0, -1],  # Tracker X -> -Probe Z (elevational)\n",
    "                [1, 0, 0],  # Tracker Y -> Probe X (lateral)\n",
    "                [0, -1, 0],  # Tracker Z -> -Probe Y (axial)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        frame_corners = frame_corners @ transform_matrix.T\n",
    "\n",
    "        # Add offset for marker to probe bottom\n",
    "        frame_corners[:, 2] += marker_to_probe_bottom\n",
    "\n",
    "        # Transform frame corners to world coordinates\n",
    "        world_corners = (\n",
    "            np.einsum(\"ij,kj->ki\", rotation_matrix, frame_corners) + position\n",
    "        )\n",
    "\n",
    "        corners_list.append(world_corners.flatten())\n",
    "\n",
    "    corners_array = np.array(corners_list)\n",
    "    corners_columns = [\n",
    "        f\"corner_{i}_{axis}\" for i in range(4) for axis in [\"x\", \"y\", \"z\"]\n",
    "    ]\n",
    "    corners_df = pd.DataFrame(corners_array, columns=corners_columns)\n",
    "\n",
    "    return corners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe specifications\n",
    "probe_specs = {\n",
    "    \"width\": 38,  # mm\n",
    "    \"height\": 50,  # mm\n",
    "    \"marker_to_probe_bottom\": 54,  # mm\n",
    "}\n",
    "\n",
    "corners_df = calculate_frame_corners(\n",
    "    df,\n",
    "    probe_specs[\"width\"],\n",
    "    probe_specs[\"height\"],\n",
    "    probe_specs[\"marker_to_probe_bottom\"],\n",
    ")\n",
    "new_df = pd.concat(\n",
    "    [\n",
    "        df.drop(\n",
    "            columns=[\n",
    "                \"ot_pos_x\",\n",
    "                \"ot_pos_y\",\n",
    "                \"ot_pos_z\",\n",
    "                \"ot_qw\",\n",
    "                \"ot_qx\",\n",
    "                \"ot_qy\",\n",
    "                \"ot_qz\",\n",
    "            ]\n",
    "        ),\n",
    "        corners_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444808f0-1f7c-4415-9eea-7e540cd93e2f",
   "metadata": {},
   "source": [
    "## 4. Create Dataset for Optical Flow and IMU Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a9ca6-5870-49ef-ad76-cc2f59a89589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpticalFlowDataset(Dataset):\n",
    "    def __init__(self, df, sequence_length=2, transform=None, downsample_factor=3):\n",
    "        self.df = df\n",
    "        self.sequence_length = sequence_length\n",
    "        self.transform = transform\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx : idx + self.sequence_length]\n",
    "\n",
    "        # Convert frames to tensors\n",
    "        frame1 = (\n",
    "            torch.tensor(np.stack(sequence[\"frame\"].iloc[0])).float().permute(2, 0, 1)\n",
    "        )\n",
    "        frame2 = (\n",
    "            torch.tensor(np.stack(sequence[\"frame\"].iloc[1])).float().permute(2, 0, 1)\n",
    "        )\n",
    "\n",
    "        # Convert IMU data to numeric, raising an error if any non-numeric values are found\n",
    "        imu_data = pd.to_numeric(\n",
    "            sequence.iloc[1][\n",
    "                [\n",
    "                    \"imu_acc_x\",\n",
    "                    \"imu_acc_y\",\n",
    "                    \"imu_acc_z\",\n",
    "                    \"imu_orientation_x\",\n",
    "                    \"imu_orientation_y\",\n",
    "                    \"imu_orientation_z\",\n",
    "                ]\n",
    "            ],\n",
    "            errors=\"raise\",\n",
    "        ).values  # Raises an error if non-numeric data is encountered\n",
    "\n",
    "        imu_data = torch.tensor(imu_data).float()\n",
    "\n",
    "        # Convert target data to numeric, raising an error if any non-numeric values are found\n",
    "        target = pd.to_numeric(\n",
    "            sequence.iloc[1][\n",
    "                [\n",
    "                    \"corner_0_x\",\n",
    "                    \"corner_0_y\",\n",
    "                    \"corner_0_z\",\n",
    "                    \"corner_1_x\",\n",
    "                    \"corner_1_y\",\n",
    "                    \"corner_1_z\",\n",
    "                    \"corner_2_x\",\n",
    "                    \"corner_2_y\",\n",
    "                    \"corner_2_z\",\n",
    "                    \"corner_3_x\",\n",
    "                    \"corner_3_y\",\n",
    "                    \"corner_3_z\",\n",
    "                ]\n",
    "            ],\n",
    "            errors=\"raise\",\n",
    "        ).values  # Raises an error if non-numeric data is encountered\n",
    "\n",
    "        target = torch.tensor(target).float()\n",
    "\n",
    "        return frame1, frame2, imu_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "optical_flow_dataset = OpticalFlowDataset(new_df)\n",
    "\n",
    "# Split the dataset\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(optical_flow_dataset)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(optical_flow_dataset, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(optical_flow_dataset, batch_size=1, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5440df-9aba-4ca1-be83-6efcb135446b",
   "metadata": {},
   "source": [
    "## 5. Define RAFT Model for Optical Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c0165-7be5-4132-baf1-8ce5591a274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained RAFT model from torchvision\n",
    "weights = Raft_Small_Weights.DEFAULT\n",
    "raft_model = raft_small(weights=weights).eval().cuda()\n",
    "\n",
    "# RAFT normalization and utility function\n",
    "transforms_raft = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputPadder:\n",
    "    \"\"\"Pads images such that dimensions are divisible by 8.\"\"\"\n",
    "\n",
    "    def __init__(self, dims, mode=\"constant\"):\n",
    "        self.ht, self.wd = dims[-2:]\n",
    "        pad_ht = (((self.ht // 8) + 1) * 8 - self.ht) % 8\n",
    "        pad_wd = (((self.wd // 8) + 1) * 8 - self.wd) % 8\n",
    "        self._pad = [\n",
    "            pad_wd // 2,\n",
    "            pad_wd - pad_wd // 2,\n",
    "            pad_ht // 2,\n",
    "            pad_ht - pad_ht // 2,\n",
    "        ]\n",
    "        self.mode = mode\n",
    "\n",
    "    def pad(self, *inputs):\n",
    "        return [nn.functional.pad(x, self._pad, mode=self.mode) for x in inputs]\n",
    "\n",
    "    def unpad(self, *inputs):\n",
    "        ht, wd = self.ht, self.wd\n",
    "        return [\n",
    "            x[..., self._pad[2] : ht + self._pad[2], self._pad[0] : wd + self._pad[0]]\n",
    "            for x in inputs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optical_flow(frame1, frame2, model, device, downsample_factor=3):\n",
    "    # Get the original size\n",
    "    original_size = frame1.shape[-2:]  # (height, width)\n",
    "\n",
    "    # Compute the downsampled size\n",
    "    downsampled_height = original_size[0] // downsample_factor\n",
    "    downsampled_width = original_size[1] // downsample_factor\n",
    "\n",
    "    # Find the nearest multiples of 8\n",
    "    adjusted_height = (downsampled_height + 7) // 8 * 8\n",
    "    adjusted_width = (downsampled_width + 7) // 8 * 8\n",
    "\n",
    "    # Resize the frames to the adjusted size\n",
    "    frame1 = F.resize(frame1, size=[adjusted_height, adjusted_width], antialias=False)\n",
    "    frame2 = F.resize(frame2, size=[adjusted_height, adjusted_width], antialias=False)\n",
    "\n",
    "    # Apply the RAFT-specific transformation to both images together\n",
    "    frame1, frame2 = transforms_raft(frame1, frame2)\n",
    "\n",
    "    # Move the transformed images to the GPU\n",
    "    frame1, frame2 = frame1.to(device), frame2.to(device)\n",
    "\n",
    "    # Pass the two images as separate arguments to the RAFT model\n",
    "    with torch.no_grad():\n",
    "        flow_list = model(frame1, frame2)\n",
    "\n",
    "    # Return the last predicted flow from the model\n",
    "    return flow_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fab3c-36cd-4ed8-9638-8cd23fee3451",
   "metadata": {},
   "source": [
    "## 6. Define Frame Corner Prediction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57057bf7-1b80-4641-a0c3-b8e5eaae8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameCornerPredictionModel(nn.Module):\n",
    "    def __init__(self, input_channels=2):\n",
    "        super(FrameCornerPredictionModel, self).__init__()\n",
    "\n",
    "        # Optical flow encoder\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # IMU encoder\n",
    "        self.fc_imu = nn.Sequential(\n",
    "            nn.Linear(6, 128), nn.ReLU(), nn.Linear(128, 128), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Placeholder for dynamically sized fc layer\n",
    "        self.fc_corners = None\n",
    "\n",
    "    def forward(self, flow, imu_data):\n",
    "        # Move everything to the same device as `flow`\n",
    "        device = flow.device\n",
    "        imu_data = imu_data.to(device)\n",
    "\n",
    "        # Pass through conv layers\n",
    "        x = self.pool(torch.relu(self.conv1(flow)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "\n",
    "        # Dynamically calculate the size after conv layers\n",
    "        batch_size = x.size(0)\n",
    "        conv_output_dim = x.size(1) * x.size(2) * x.size(3)\n",
    "\n",
    "        # If fc_corners is not initialized, initialize it now with the correct input size\n",
    "        if self.fc_corners is None:\n",
    "            self.fc_corners = nn.Sequential(\n",
    "                nn.Linear(conv_output_dim + 128, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 12),  # 12 values for 4 corners (x, y, z) * 4\n",
    "            ).to(device)\n",
    "\n",
    "        x = x.view(batch_size, -1)  # Flatten the output\n",
    "\n",
    "        imu_features = self.fc_imu(imu_data)\n",
    "\n",
    "        combined_features = torch.cat((x, imu_features), dim=1)\n",
    "\n",
    "        corners = self.fc_corners(combined_features)\n",
    "\n",
    "        return corners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a38342-27c1-448a-abe0-193816b07fcf",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8d63e-420a-4a87-ae9b-d18222c9e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FrameCornerPredictionModel().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=100000,\n",
    "    patience=10,\n",
    "    downsample_factor=3,\n",
    "):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\", position=0):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        epoch_progress = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", position=1, leave=False\n",
    "        )\n",
    "\n",
    "        for frame1, frame2, imu_data, targets in epoch_progress:\n",
    "            frame1, frame2, imu_data, targets = (\n",
    "                frame1.to(device),\n",
    "                frame2.to(device),\n",
    "                imu_data.to(device),\n",
    "                targets.to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute optical flow using RAFT with the downsample factor\n",
    "            flow = compute_optical_flow(\n",
    "                frame1, frame2, raft_model, device, downsample_factor\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(flow, imu_data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_loss_avg = train_loss / (epoch_progress.n + 1)\n",
    "            epoch_progress.set_postfix({\"Avg Loss\": f\"{train_loss_avg:.4f}\"})\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for frame1, frame2, imu_data, targets in val_loader:\n",
    "                frame1, frame2, imu_data, targets = (\n",
    "                    frame1.to(device),\n",
    "                    frame2.to(device),\n",
    "                    imu_data.to(device),\n",
    "                    targets.to(device),\n",
    "                )\n",
    "                flow = compute_optical_flow(\n",
    "                    frame1, frame2, raft_model, device, downsample_factor\n",
    "                )\n",
    "                outputs = model(flow, imu_data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss_avg:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                tqdm.write(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "torch.save(trained_model.state_dict(), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd3e3c-a33f-46c9-94c1-9167c2312b9b",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63712ab0-f52c-4c7a-b2c5-c616c230d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, downsample_factor=3):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frame1, frame2, imu_data, targets in data_loader:\n",
    "            frame1, frame2, imu_data, targets = (\n",
    "                frame1.to(device),\n",
    "                frame2.to(device),\n",
    "                imu_data.to(device),\n",
    "                targets.to(device),\n",
    "            )\n",
    "            flow = compute_optical_flow(\n",
    "                frame1, frame2, raft_model, device, downsample_factor\n",
    "            )\n",
    "            outputs = model(flow, imu_data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return avg_loss, all_predictions, all_targets\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_predictions, val_targets = evaluate_model(trained_model, val_loader)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cd73e-2664-45cd-85b2-6d735bf424cb",
   "metadata": {},
   "source": [
    "## 9. Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb5611-5d3c-4702-a5f9-6404bb346892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(predictions, targets):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Plot ground truth corners\n",
    "    for i in range(4):\n",
    "        ax.scatter(\n",
    "            targets[:, i * 3],\n",
    "            targets[:, i * 3 + 1],\n",
    "            targets[:, i * 3 + 2],\n",
    "            label=f\"Ground Truth Corner {i+1}\",\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    # Plot predicted corners\n",
    "    for i in range(4):\n",
    "        ax.scatter(\n",
    "            predictions[:, i * 3],\n",
    "            predictions[:, i * 3 + 1],\n",
    "            predictions[:, i * 3 + 2],\n",
    "            label=f\"Predicted Corner {i+1}\",\n",
    "            marker=\"x\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_title(\"Predicted vs Ground Truth Corners\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_predictions(val_predictions, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abusfusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
