{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1091009-4e30-437d-ac9b-6dea60f17e3a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " # 3D Ultrasound Volume Reconstruction\n",
    "\n",
    " This notebook demonstrates how to load ultrasound data from an HDF5 file, train a model to predict transformation parameters, and visualize the 3D volume reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f751078-2be1-4360-9577-426fcd9e9a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m/home/varun/xia_lab/repos/ABUSFusion/notebooks/new.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m efficientnet_b1\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmpl_toolkits\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmplot3d\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes3D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_b1\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Import custom modules\n",
    "from freehand.network import build_model\n",
    "from freehand.transform import (\n",
    "    LabelTransform,\n",
    "    PredictionTransform,\n",
    "    TransformAccumulation,\n",
    ")\n",
    "from freehand.utils import pair_samples, reference_image_points, type_dim\n",
    "from freehand.loss import PointDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fced1cb-2927-487f-8628-670472fb7c3b",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81349666-b734-4c7f-a3b2-9348c8a787c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, num_samples=10, sample_range=10):\n",
    "        self.data = pd.read_hdf(hdf5_file)\n",
    "        self.num_samples = num_samples\n",
    "        self.sample_range = sample_range\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sample_range + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx : idx + self.sample_range]\n",
    "        frames = torch.tensor(\n",
    "            np.stack(sample[\"ultrasound_frame\"].values), dtype=torch.float32\n",
    "        )\n",
    "        imu_data = torch.tensor(\n",
    "            sample[\n",
    "                [\n",
    "                    \"acceleration_x\",\n",
    "                    \"acceleration_y\",\n",
    "                    \"acceleration_z\",\n",
    "                    \"orientation_x\",\n",
    "                    \"orientation_y\",\n",
    "                    \"orientation_z\",\n",
    "                ]\n",
    "            ].values,\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        ot_data = torch.tensor(\n",
    "            sample[\n",
    "                [\n",
    "                    \"ot_position_x\",\n",
    "                    \"ot_position_y\",\n",
    "                    \"ot_position_z\",\n",
    "                    \"ot_orientation_x\",\n",
    "                    \"ot_orientation_y\",\n",
    "                    \"ot_orientation_z\",\n",
    "                ]\n",
    "            ].values,\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        return frames, imu_data, ot_data\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = UltrasoundDataset(\"path/to/your/hdf5_file.h5\")\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb894c-09e9-42ed-842b-9e62c3182583",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Define Model and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a72526-fb45-44ac-8fa5-0cd72ecdc14c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters\n",
    "NUM_SAMPLES = 10\n",
    "NUM_PRED = 9\n",
    "PRED_TYPE = \"parameter\"\n",
    "LABEL_TYPE = \"point\"\n",
    "\n",
    "# Training parameters\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Create model\n",
    "frame_size = dataset.data[\"ultrasound_frame\"].iloc[0].shape\n",
    "image_points = reference_image_points(frame_size, 2).to(device)\n",
    "data_pairs = pair_samples(NUM_SAMPLES, NUM_PRED).to(device)\n",
    "pred_dim = type_dim(PRED_TYPE, image_points.shape[1], data_pairs.shape[0])\n",
    "\n",
    "model = build_model(efficientnet_b1, in_frames=NUM_SAMPLES, out_dim=pred_dim).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113b1ee-7d34-411b-9423-32a866fe2e91",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16be28-70a0-4964-b702-98dc4e3c91a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (frames, imu_data, ot_data) in enumerate(dataloader):\n",
    "            frames, imu_data, ot_data = (\n",
    "                frames.to(device),\n",
    "                imu_data.to(device),\n",
    "                ot_data.to(device),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(frames)\n",
    "\n",
    "            # Compute loss (you may need to adjust this based on your specific requirements)\n",
    "            loss = criterion(\n",
    "                outputs, ot_data[:, -1, :]\n",
    "            )  # Predict the last frame's OT data\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988938a5-c834-4bf6-969d-99a43c293315",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Visualize 3D Volume Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72c35f-570f-4fe1-a063-83b1595e1665",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "def visualize_3d_volume(predicted_params, frame_size):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Convert predicted parameters to 3D points (this is a placeholder, adjust based on your transformation method)\n",
    "    x = predicted_params[:, 0]\n",
    "    y = predicted_params[:, 1]\n",
    "    z = predicted_params[:, 2]\n",
    "\n",
    "    # Plot the points\n",
    "    ax.scatter(x, y, z, c=range(len(x)), cmap=\"viridis\")\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_title(\"Reconstructed 3D Ultrasound Volume\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Perform inference on a sample\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_frames, _, _ = next(iter(dataloader))\n",
    "    sample_frames = sample_frames.to(device)\n",
    "    predicted_params = model(sample_frames)\n",
    "\n",
    "visualize_3d_volume(predicted_params.cpu().numpy(), frame_size)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
