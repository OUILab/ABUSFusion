{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to abusfusion (Python 3.12.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfba459-7643-41a0-b06d-4acf4f839789",
   "metadata": {},
   "source": [
    "# 6DoF Pose Estimation with Ultrasound Frames and IMU Data Using Mamba SSM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056c9e9-2c63-4147-8d94-57ff2a9ffdb1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676245fc-390a-4f4b-b6ce-8f9efeb8c9f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mambassm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mUntitled-1:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmambassm\u001b[39;00m \u001b[39mimport\u001b[39;00m MambaSSM  \u001b[39m# Import Mamba SSM\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mambassm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from mambassm import MambaSSM  # Import Mamba SSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916661bb-cc17-4e37-b893-72d5bbfb6f9f",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc5699-c78b-4a99-a10f-ece066070d42",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_hdf(file_path)\n",
    "\n",
    "\n",
    "file_path = \"/path/to/your/data.h5\"\n",
    "df = load_data(file_path)\n",
    "\n",
    "# Ensure data is numeric\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3e323-befb-4485-b472-55bad0077268",
   "metadata": {},
   "source": [
    "## 3. Create Dataset for 6DoF Pose Estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ad7d5-66ca-4586-b984-21093938a183",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "class PoseEstimationDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, downsample_factor=3):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load and process ultrasound frame\n",
    "        frame = torch.tensor(np.stack(row[\"frame\"])).float().permute(2, 0, 1)\n",
    "        if self.downsample_factor > 1:\n",
    "            frame = F.resize(\n",
    "                frame,\n",
    "                [\n",
    "                    frame.shape[1] // self.downsample_factor,\n",
    "                    frame.shape[2] // self.downsample_factor,\n",
    "                ],\n",
    "            )\n",
    "\n",
    "        # IMU data\n",
    "        imu_data = torch.tensor(\n",
    "            [\n",
    "                row[\"imu_acc_x\"],\n",
    "                row[\"imu_acc_y\"],\n",
    "                row[\"imu_acc_z\"],\n",
    "                row[\"imu_orientation_x\"],\n",
    "                row[\"imu_orientation_y\"],\n",
    "                row[\"imu_orientation_z\"],\n",
    "            ]\n",
    "        ).float()\n",
    "\n",
    "        # 6DoF pose as target\n",
    "        target = torch.tensor(\n",
    "            [\n",
    "                row[\"ot_pos_x\"],\n",
    "                row[\"ot_pos_y\"],\n",
    "                row[\"ot_pos_z\"],\n",
    "                row[\"ot_qw\"],\n",
    "                row[\"ot_qx\"],\n",
    "                row[\"ot_qy\"],\n",
    "                row[\"ot_qz\"],\n",
    "            ]\n",
    "        ).float()\n",
    "\n",
    "        return frame, imu_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda4b9e-dbbb-47d6-94b6-a47cf00cb17a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "pose_dataset = PoseEstimationDataset(df)\n",
    "\n",
    "# Split the dataset\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(pose_dataset)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(pose_dataset, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(pose_dataset, batch_size=1, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5890427-a1f2-497b-b71e-00f8240b5ed5",
   "metadata": {},
   "source": [
    "## 4. Define Model for 6DoF Pose Estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f6049-d765-4cfa-979a-12f02de1874c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "class PoseEstimationModel(nn.Module):\n",
    "    def __init__(self, input_channels=3, downsample_factor=3):\n",
    "        super(PoseEstimationModel, self).__init__()\n",
    "\n",
    "        # CNN for ultrasound frames\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Mamba SSM for IMU data\n",
    "        self.ssm = MambaSSM(\n",
    "            input_dim=6, hidden_dim=64, num_layers=2, bidirectional=False\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for 6DoF pose\n",
    "        conv_output_height = 1000 // (\n",
    "            4 * downsample_factor\n",
    "        )  # Adjusted based on downsampling\n",
    "        conv_output_width = 657 // (\n",
    "            4 * downsample_factor\n",
    "        )  # Adjusted based on downsampling\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * conv_output_height * conv_output_width + 64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                256, 7\n",
    "            ),  # 7 values: 3 for translation, 4 for rotation (quaternion)\n",
    "        )\n",
    "\n",
    "    def forward(self, frame, imu_data):\n",
    "        # CNN for ultrasound frames\n",
    "        x = self.pool(torch.relu(self.conv1(frame)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "\n",
    "        # Mamba SSM for IMU data\n",
    "        imu_data = imu_data.unsqueeze(1)  # Add sequence length dimension (assumed 1)\n",
    "        ssm_out, _ = self.ssm(imu_data)\n",
    "        ssm_out = ssm_out[:, -1, :]  # Take the last output of the sequence\n",
    "\n",
    "        # Concatenate CNN and SSM outputs\n",
    "        combined = torch.cat((x, ssm_out), dim=1)\n",
    "\n",
    "        # Fully connected layers for 6DoF pose\n",
    "        output = self.fc(combined)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0abccd-f695-45c2-a09a-f54dcb713b29",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3918241-2fe3-4e2d-bfc3-ae6dc0844c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PoseEstimationModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0835b-c881-42cf-8897-d33ae7b00595",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=50,\n",
    "    patience=10,\n",
    "):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\", position=0):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        epoch_progress = tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", position=1, leave=False\n",
    "        )\n",
    "\n",
    "        for frames, imu_data, targets in epoch_progress:\n",
    "            frames, imu_data, targets = (\n",
    "                frames.to(device),\n",
    "                imu_data.to(device),\n",
    "                targets.to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(frames, imu_data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_loss_avg = train_loss / (epoch_progress.n + 1)\n",
    "            epoch_progress.set_postfix({\"Avg Loss\": f\"{train_loss_avg:.4f}\"})\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for frames, imu_data, targets in val_loader:\n",
    "                frames, imu_data, targets = (\n",
    "                    frames.to(device),\n",
    "                    imu_data.to(device),\n",
    "                    targets.to(device),\n",
    "                )\n",
    "                outputs = model(frames, imu_data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss_avg:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                tqdm.write(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7571e-def6-4f4b-90bc-93de9792b6d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "torch.save(trained_model.state_dict(), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56852a3-fe9a-421e-87eb-56e5e0219da0",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e8585-1ae5-412a-a55a-6e98323e44d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frames, imu_data, targets in data_loader:\n",
    "            frames, imu_data, targets = (\n",
    "                frames.to(device),\n",
    "                imu_data.to(device),\n",
    "                targets.to(device),\n",
    "            )\n",
    "            outputs = model(frames, imu_data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return avg_loss, all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7b962-64bf-468c-9ac5-c07e1a7c15cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "val_loss, val_predictions, val_targets = evaluate_model(trained_model, val_loader)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc98b9-fd75-4db3-83a4-78c24f8391f5",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb311a2-00b5-4e35-95ba-3482f2e3467c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "def visualize_predictions(predictions, targets):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Plot ground truth positions\n",
    "    ax.scatter(\n",
    "        targets[:, 0], targets[:, 1], targets[:, 2], label=\"Ground Truth\", marker=\"o\"\n",
    "    )\n",
    "\n",
    "    # Plot predicted positions\n",
    "    ax.scatter(\n",
    "        predictions[:, 0],\n",
    "        predictions[:, 1],\n",
    "        predictions[:, 2],\n",
    "        label=\"Predicted\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_title(\"Predicted vs Ground Truth Positions\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_predictions(val_predictions, val_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abusfusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
